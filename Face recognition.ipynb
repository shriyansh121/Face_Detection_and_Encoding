{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af995386-5fe1-41e3-b460-be9aa8ffaa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21801ca7-c068-4eda-a2e9-39b6b6318e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Using opencv to write text on frame on different positions.'''\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    r,frame = cap.read()\n",
    "    frame_height, frame_width = frame.shape[0], frame.shape[1]\n",
    "    \n",
    "    cv2.putText(frame, org = (10,50), text = \"Top Left\", fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=2, color =(0,255,200) , thickness=4 )\n",
    "\n",
    "    cv2.putText(frame, org = (frame_width-320, 50), text = \"Top Right\", fontFace =cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               fontScale = 2, color= (255,100,100), thickness=4)\n",
    "\n",
    "    cv2.putText(frame, org = (10,frame_height-50), text = \"Bottom Left\", fontFace = cv2.FONT_HERSHEY_SIMPLEX, \n",
    "               fontScale=2, color = (255,60,190), thickness=4)\n",
    "\n",
    "    cv2.putText(frame,org = (frame_width-430, frame_height-50), text = \"Bottom Right\", fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               fontScale=2, color = (25,170,80), thickness=4)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(4) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23374e31-9f6c-4ded-8ef3-e7832cd7eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Using opencv to count frame and calculate frame per second(fps)'''\n",
    "cap = cv2.VideoCapture(0)\n",
    "frame_count=0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    r,frame = cap.read()\n",
    "    frame_count+=1\n",
    "\n",
    "    elapsed_time = time.time()-start_time\n",
    "    fps = frame_count/elapsed_time\n",
    "\n",
    "    cv2.putText(frame,org =(100,100), text = f\"Frame Count: {frame_count}\", fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "               fontScale=3, color = (255,100,170), thickness=4)\n",
    "\n",
    "    cv2.putText(frame , org = (100,200), text=f\"FPS: {fps}\", fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "               fontScale=3, color=(255,255,60), thickness=4)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(5) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00669a50-ea1e-42c0-8ba2-79dc4e94ee38",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35589a61-9652-4828-8f12-76cede88419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shriyansh_image = face_recognition.load_image_file(\"/Users/shriyansh/Desktop/Photo on 01-02-25 at 11.30 PM.jpg\")\n",
    "# shriyansh_encodings = face_recognition.face_encodings(shriyansh_image)[0]\n",
    "\n",
    "messi_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/messi.jpg\")\n",
    "messi_encodings = face_recognition.face_encodings(messi_image)[0]\n",
    "\n",
    "harry_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-07 at 8.41.13 PM.png\")\n",
    "harry_encodings = face_recognition.face_encodings(harry_image)[0]\n",
    "\n",
    "hermione_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-07 at 8.39.20 PM.png\")\n",
    "hermione_encodings = face_recognition.face_encodings(hermione_image)[0]\n",
    "\n",
    "ron_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-07 at 8.41.21 PM.png\")\n",
    "ron_encodings = face_recognition.face_encodings(ron_image)[0]\n",
    "\n",
    "known_face_encodings = [messi_encodings, harry_encodings, hermione_encodings, ron_encodings,shriyansh_encodings]\n",
    "known_face_names = ['Lionel Messi', 'Harry Potter', 'Hermione Granger', 'Ron Wisley', 'Shriyansh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d0fd10c-0b82-446f-97c1-972aa704f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "start_time = time.time()\n",
    "frame_count=0\n",
    "process_this_frame = True\n",
    "\n",
    "while True:\n",
    "    r,frame = cap.read()\n",
    "    if not r:\n",
    "        print(\"Frame not captured.\")\n",
    "    frame_count+=1\n",
    "    elapsed_time = time.time() - start_time\n",
    "    fps = frame_count/elapsed_time\n",
    "\n",
    "\n",
    "    cv2.putText(frame,  org = (100,100),  text = f\"Frame count: {frame_count}\",  fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "               fontScale= 2, color=(153,51,0), thickness=2)\n",
    "    cv2.putText(frame, org = (100,200), text = f\"FPS: {fps}\", fontFace = cv2.FONT_HERSHEY_DUPLEX,\n",
    "               fontScale=2, color = (51,51,0), thickness=2)\n",
    "    \n",
    "    processing_frame = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)\n",
    "    processing_frame = cv2.cvtColor(processing_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if process_this_frame:\n",
    "        face_locations = face_recognition.face_locations(processing_frame)\n",
    "        face_encodings = face_recognition.face_encodings(processing_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"unknown\"\n",
    "            \n",
    "            face_distance = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_index = np.argmin(face_distance)\n",
    "\n",
    "            if matches[best_index]:\n",
    "                name = known_face_names[best_index]\n",
    "            face_names.append(name)\n",
    "    process_this_frame= not process_this_frame\n",
    "    for (top,right,bottom,left),name in zip(face_locations,face_names):\n",
    "        top *=4\n",
    "        bottom*=4\n",
    "        right*=4\n",
    "        left*=4\n",
    "        cv2.rectangle(frame, (left,top), (right,bottom), (255,255,0), 2)\n",
    "        cv2.rectangle(frame, (left,bottom), (right,bottom+35), (255,255,0),cv2.FILLED)\n",
    "        cv2.putText(frame, name, (left+6,bottom+30), cv2.FONT_HERSHEY_DUPLEX, 1.5, (0,0,0),2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(5) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37469fc3-45cf-42f0-adf4-1d1fc3c2d75f",
   "metadata": {},
   "source": [
    "# Capturing real time images and Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74a0bc97-c8b1-4b54-80cc-43641ba7aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "messi_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/messi.jpg\")\n",
    "messi_encodings = face_recognition.face_encodings(messi_image)[0]\n",
    "\n",
    "harry_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-07 at 8.41.13 PM.png\")\n",
    "harry_encodings = face_recognition.face_encodings(harry_image)[0]\n",
    "\n",
    "hermione_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-07 at 8.39.20 PM.png\")\n",
    "hermione_encodings = face_recognition.face_encodings(hermione_image)[0]\n",
    "\n",
    "ron_image = face_recognition.load_image_file(\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Screenshot 2025-03-07 at 8.41.21 PM.png\")\n",
    "ron_encodings = face_recognition.face_encodings(ron_image)[0]\n",
    "\n",
    "known_face_encodings = [messi_encodings, harry_encodings, hermione_encodings, ron_encodings,shriyansh_encodings]\n",
    "known_face_names = ['Lionel Messi', 'Harry Potter', 'Hermione Granger', 'Ron Wisley', 'Shriyansh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58ed255e-8c80-4cda-a7a1-a5a89ebbaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of person Vipin Sen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image for Vipin Sen captured and stored as /Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/Vipin Sen.jpg\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    r,frame = cap.read()\n",
    "\n",
    "    cv2.putText(frame, org = (300,100), text= \"Only one person in a frame\", fontFace = cv2.FONT_HERSHEY_DUPLEX,\n",
    "                fontScale = 1.5,color = (255,255,255), thickness=2)\n",
    "    \n",
    "    cv2.imshow(\"Press c to capture the image\", frame)\n",
    "    if cv2.waitKey(9) & 0xFF==ord('c'):\n",
    "        name = input(\"Enter the name of person\")\n",
    "\n",
    "        image_path = f\"/Users/shriyansh/Documents/Data Science/projects/OPENCv/Face recognition/face_recog face/{name}.jpg\"\n",
    "        cv2.imwrite(image_path,frame)\n",
    "        print(f\"Image for {name} captured and stored as {image_path}\")\n",
    "        break\n",
    "\n",
    "captured_image = face_recognition.load_image_file(image_path)\n",
    "captured_image_encodings = face_recognition.face_encodings(captured_image)[0]\n",
    "\n",
    "known_face_encodings.append(captured_image_encodings)\n",
    "known_face_names.append(name)\n",
    "\n",
    "process_this_frame=True\n",
    "frame_count=0\n",
    "fps=0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    r,frame = cap.read()\n",
    "\n",
    "    processing_frame =cv2.resize(frame, (0,0), fx=0.25, fy=0.25)\n",
    "    processing_frame = cv2.cvtColor(processing_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    frame_count+=1\n",
    "    elapsed_time = time.time()-start_time\n",
    "    fps = round(frame_count/elapsed_time,4)\n",
    "    \n",
    "    cv2.putText(frame,org = (100,100), text = f\"Frame Count: {frame_count}\", fontFace = cv2.FONT_HERSHEY_DUPLEX, fontScale=2, \n",
    "               color = (255,102,0), thickness=2)\n",
    "    cv2.putText(frame,org = (100,200), text = f\"FPS: {fps}\", fontFace= cv2.FONT_HERSHEY_DUPLEX, fontScale=2, \n",
    "               color = (255,153,0), thickness=2)\n",
    "\n",
    "    if process_this_frame:\n",
    "        face_locations = face_recognition.face_locations(processing_frame)\n",
    "        face_encodings = face_recognition.face_encodings(processing_frame, face_locations)\n",
    "\n",
    "        face_names=[]\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"unknown\"\n",
    "\n",
    "            face_names=[]\n",
    "            face_distance = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_index = np.argmin(face_distance)\n",
    "            if matches[best_index]:\n",
    "                name = known_face_names[best_index]\n",
    "            face_names.append(name)\n",
    "\n",
    "    for (top, right, bottom, left),name in zip(face_locations,face_names):\n",
    "        top*=4\n",
    "        right*=4\n",
    "        bottom*=4\n",
    "        left*=4\n",
    "        cv2.rectangle(frame,(left,top), (right, bottom), (0,255,0), 2 )\n",
    "        cv2.rectangle(frame, (left,bottom),(right, bottom+40), (0,255,255), cv2.FILLED)\n",
    "        cv2.putText(frame, org = (left+10, bottom+35),text = name, fontFace=cv2.FONT_HERSHEY_DUPLEX, \n",
    "                    fontScale = 1.5,color = (0,51,0),thickness=1)\n",
    "    cv2.imshow(\"Face Recognition Frame\", frame)\n",
    "    if cv2.waitKey(4) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
